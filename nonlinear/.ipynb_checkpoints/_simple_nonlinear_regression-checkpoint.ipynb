{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      WL1(mm)  WL2(mm)  WL3(mm)  WL4 (mm)  WL5 (mm)  Solar (W/m2)  \\\n",
      "0          65      213       94        37        43           415   \n",
      "1          65      211      101        37        43           329   \n",
      "2          66      211      102        36        43           115   \n",
      "3          64      212       88        36        43            31   \n",
      "4          65      210       95        36        43             1   \n",
      "...       ...      ...      ...       ...       ...           ...   \n",
      "1425       39       41       41        36        44           665   \n",
      "1426       39       41       41        36        43           557   \n",
      "1427       39       41       41        37        44           395   \n",
      "1428       39       41       41        36        43           208   \n",
      "1429       39       41       41        36        44            44   \n",
      "\n",
      "      Precipitation (mm)  AirTemp (DegC)  RH (%)  PD (mm)  \n",
      "0                  0.000            34.0      51     70.5  \n",
      "1                  0.000            33.5      67     72.7  \n",
      "2                  0.000            32.8      68     72.4  \n",
      "3                  0.000            30.8      78     72.5  \n",
      "4                  0.000            28.9      87     72.4  \n",
      "...                  ...             ...     ...      ...  \n",
      "1425               0.017            24.9      47     54.9  \n",
      "1426               0.017            24.9      44     54.4  \n",
      "1427               0.000            24.6      43     51.6  \n",
      "1428               0.017            23.9      44     48.6  \n",
      "1429               0.017            22.3      43     46.6  \n",
      "\n",
      "[1430 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "data_display = pd.read_csv(\"parsed_alldata.csv\")\n",
    "\n",
    "print(data_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "trainning_steps = 50000\n",
    "display_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"parsed_alldata_np.csv\", delimiter = ',', dtype = np.float32)\n",
    "\n",
    "x_train = data[:1200, [0]]\n",
    "y_train = data[:1200, [-1]]\n",
    "\n",
    "x_test = data[1200:, [0]]\n",
    "y_test = data[1200:, [-1]]\n",
    "\n",
    "w1 = tf.Variable(random.random())\n",
    "w2 = tf.Variable(random.random())\n",
    "bias = tf.Variable(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000 \n",
      " w1: 0.10631179 \n",
      " w2: 0.18981613 \n",
      " bias: -0.33459637 \n",
      " loss: 77287.81 \n",
      "\n",
      "step: 2000 \n",
      " w1: 0.017599428 \n",
      " w2: 0.11953322 \n",
      " bias: -0.38481858 \n",
      " loss: 1487.5743 \n",
      "\n",
      "step: 3000 \n",
      " w1: 0.01591983 \n",
      " w2: 0.15241897 \n",
      " bias: -0.31438935 \n",
      " loss: 1427.9304 \n",
      "\n",
      "step: 4000 \n",
      " w1: 0.01502989 \n",
      " w2: 0.20880282 \n",
      " bias: -0.19621602 \n",
      " loss: 1351.323 \n",
      "\n",
      "step: 5000 \n",
      " w1: 0.013606615 \n",
      " w2: 0.29903457 \n",
      " bias: -0.008800138 \n",
      " loss: 1233.2562 \n",
      "\n",
      "step: 6000 \n",
      " w1: 0.011406813 \n",
      " w2: 0.4385868 \n",
      " bias: 0.27497196 \n",
      " loss: 1061.681 \n",
      "\n",
      "step: 7000 \n",
      " w1: 0.008171595 \n",
      " w2: 0.6441112 \n",
      " bias: 0.67508906 \n",
      " loss: 833.40607 \n",
      "\n",
      "step: 8000 \n",
      " w1: 0.003763392 \n",
      " w2: 0.92480123 \n",
      " bias: 1.1832501 \n",
      " loss: 568.2647 \n",
      "\n",
      "step: 9000 \n",
      " w1: -0.0016132587 \n",
      " w2: 1.2681268 \n",
      " bias: 1.7502173 \n",
      " loss: 315.93307 \n",
      "\n",
      "step: 10000 \n",
      " w1: -0.007264048 \n",
      " w2: 1.6298524 \n",
      " bias: 2.29988 \n",
      " loss: 134.13126 \n",
      "\n",
      "step: 11000 \n",
      " w1: -0.012121676 \n",
      " w2: 1.94121 \n",
      " bias: 2.753607 \n",
      " loss: 45.715675 \n",
      "\n",
      "step: 12000 \n",
      " w1: -0.015193151 \n",
      " w2: 2.1378613 \n",
      " bias: 3.0549276 \n",
      " loss: 22.089048 \n",
      "\n",
      "step: 13000 \n",
      " w1: -0.016340021 \n",
      " w2: 2.2104287 \n",
      " bias: 3.2173421 \n",
      " loss: 19.66561 \n",
      "\n",
      "step: 14000 \n",
      " w1: -0.016496494 \n",
      " w2: 2.2185917 \n",
      " bias: 3.3398328 \n",
      " loss: 19.552847 \n",
      "\n",
      "step: 15000 \n",
      " w1: -0.016456177 \n",
      " w2: 2.2129118 \n",
      " bias: 3.51482 \n",
      " loss: 19.44957 \n",
      "\n",
      "step: 16000 \n",
      " w1: -0.016379585 \n",
      " w2: 2.2030478 \n",
      " bias: 3.7937136 \n",
      " loss: 19.285337 \n",
      "\n",
      "step: 17000 \n",
      " w1: -0.016261337 \n",
      " w2: 2.1878517 \n",
      " bias: 4.22239 \n",
      " loss: 19.034824 \n",
      "\n",
      "step: 18000 \n",
      " w1: -0.01609245 \n",
      " w2: 2.1661777 \n",
      " bias: 4.8329287 \n",
      " loss: 18.682156 \n",
      "\n",
      "step: 19000 \n",
      " w1: -0.015877029 \n",
      " w2: 2.1385312 \n",
      " bias: 5.6117396 \n",
      " loss: 18.239304 \n",
      "\n",
      "step: 20000 \n",
      " w1: -0.015633527 \n",
      " w2: 2.107195 \n",
      " bias: 6.4983287 \n",
      " loss: 17.744816 \n",
      "\n",
      "step: 21000 \n",
      " w1: -0.01538207 \n",
      " w2: 2.0745993 \n",
      " bias: 7.4240837 \n",
      " loss: 17.239374 \n",
      "\n",
      "step: 22000 \n",
      " w1: -0.015125753 \n",
      " w2: 2.0414932 \n",
      " bias: 8.363361 \n",
      " loss: 16.737877 \n",
      "\n",
      "step: 23000 \n",
      " w1: -0.014869182 \n",
      " w2: 2.0082963 \n",
      " bias: 9.306598 \n",
      " loss: 16.245796 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_loss():\n",
    "    hypothesis = w1 * x_train * x_train + w2 * x_train + bias\n",
    "    loss = tf.reduce_mean((y_train - hypothesis) ** 2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "optimizer = tf.optimizers.Adam(lr = learning_rate)\n",
    "\n",
    "for step in range(1, trainning_steps + 1):\n",
    "    optimizer.minimize(compute_loss, var_list = [w1, w2, bias])\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        print('step:', step, '\\n', 'w1:', w1.numpy(), '\\n', 'w2:', w2.numpy(), '\\n', \n",
    "              'bias:', bias.numpy(), '\\n', 'loss:', compute_loss().numpy(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
